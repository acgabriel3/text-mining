sa
regmatches( txtdf[38,2], gregexpr("(?<=DOSSIÊ TÉCNICO\n).*(?=\\nTítulo)","", txtdf[358,2], perl = TRUE ))
regmatches( txtdf[38,2], gregexpr("(?<=DOSSIÊ TÉCNICO\n).*(?=\nTítulo)","", txtdf[358,2], perl = TRUE ))
regmatches( txtdf[38,2], gregexpr("(?<=DOSSIÊ TÉCNICO\n).*(?=Título)","", txtdf[358,2], perl = TRUE ))
regmatches( txtdf[38,2], gregexpr("(?<=DOSSIÊ TÉCNICO\n).*(?=Título)", txtdf[358,2], perl = TRUE ))
regmatches( txtdf[38,2], gregexpr("(?<=DOSSIÊ TÉCNICO).*(?=Título)", txtdf[358,2], perl = TRUE ))
regmatches( txtdf[38,2], gregexpr("(?<=DOSSIÊ TÉCNICO).*(?=Título)", txtdf[358,2], perl = TRUE ))
regmatches( txtdf[38,2], gregexpr("(?<=DOSSIÊ TÉCNICO).*(?=T)", txtdf[358,2], perl = TRUE ))
regmatches( txtdf[38,2], gregexpr("(?<=D).*(?=T)", txtdf[358,2], perl = TRUE ))
regmatches( txtdf[38,2], gregexpr("(?<=DOSSI).*(?=T)", txtdf[358,2], perl = TRUE ))
regmatches( txtdf[38,2], gregexpr("(?<=DOSSI).*(?=Té)", txtdf[358,2], perl = TRUE ))
regmatches( txtdf[38,2], gregexpr("(?<=DOSSI).*(?=Te)", txtdf[358,2], perl = TRUE ))
regmatches( txtdf[38,2], gregexpr("(?<=DOSSI).*(?=Ti)", txtdf[358,2], perl = TRUE ))
regmatches( txtdf[38,2], gregexpr("(?<=DOSSI).*(?=Tí)", txtdf[358,2], perl = TRUE ))
regmatches( txtdf[38,2], gregexpr("(?<=DOSSI).*(?=muito)", txtdf[358,2], perl = TRUE ))
regmatches( txtdf[38,2], gregexpr("(?<=DOS).*(?=muito)", txtdf[358,2], perl = TRUE ))
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE
)
df_palavra <- txtdf %>%
unnest_tokens(palavra, text) %>%
filter(!palavra %in% sw_pt_tm)
df_palavra %>%
count(palavra) %>%
arrange(desc(n)) %>%
head(50) %>%
formattable()
sw_pt_tm <- tm::stopwords("pt") %>% iconv(from = "UTF-8", to = "ASCII//TRANSLIT")
sbrt_sw <- c("http", "senai", "sbrt", "deve","acesso", "brasil", "devem", "pode", "ser","norma","iso", "kg", "fig", "fonte", "sbrt", "abnt", "nbr", "tecnica")
sw_pt <- c(sbrt_sw, sw_pt_tm)
sw_pt_tm <- tm::stopwords("pt") %>% iconv(from = "UTF-8", to = "ASCII//TRANSLIT")
sbrt_sw <- c("http", "senai", "deve","acesso", "brasil", "devem", "www.respostatecnica.org.br", "pode", "ser","norma","iso", "kg", "fig", "fonte", "sbrt", "abnt", "nbr", "tecnica")
sw_pt <- c(sbrt_sw, sw_pt_tm)
df_palavra <- txtdf %>%
unnest_tokens(palavra, text) %>%
filter(!palavra %in% sw_pt_tm)
df_palavra %>%
count(palavra) %>%
arrange(desc(n)) %>%
head(50) %>%
formattable()
sw_pt_tm <- tm::stopwords("pt") %>% iconv(from = "UTF-8", to = "ASCII//TRANSLIT")
sbrt_sw <- c("http", "senai", "deve","acesso", "brasil", "devem", "www.respostatecnica.org.br", "pode", "ser","norma","iso", "kg", "fig", "fonte", "sbrt", "abnt", "nbr", "tecnica")
sw_pt_tm <- c(sbrt_sw, sw_pt_tm)
df_palavra <- txtdf %>%
unnest_tokens(palavra, text) %>%
filter(!palavra %in% sw_pt_tm)
df_palavra %>%
count(palavra) %>%
arrange(desc(n)) %>%
head(50) %>%
formattable()
#FREX apresenta as palavras que mais representam o tópico.
stm::labelTopics(fit)
head(fit$theta)
#FREX apresenta as palavras que mais representam o tópico.
stm::labelTopics(fit)
nomes_topicos <- c("1", "2", "3",
"4", "5", "6", "7",
"8", "9", "10")
maior_prob <- apply(fit$theta, 1, max)
topico_doc <- nomes_topicos[apply(fit$theta, 1, which.max)]
df_topico <- txtdf %>%
mutate(maior_prob = maior_prob,
topico = topico_doc)
roxo <- "mediumpurple4"
df_topico %>%
count(topico) %>%
mutate(topico = forcats::fct_reorder(topico, n)) %>%
ggplot(aes(x = topico, y = n)) +
geom_col(fill = "mediumpurple4") +
theme_minimal() +
labs(x = NULL, y = "Documentos",
title = "Quantidade de documentos por tópico") +
coord_flip()
gc()
options("encoding" = "UTF-8")
library(stringr)
library(tm)
library(SnowballC)
library(lexiconPT)
library(tidytext)
library(tidyverse)
library(magrittr)
library(stm)
library(ggridges)
library(formattable)
options(scipen = 999)
dados<-"/home/micael/R_envs/text-mining/dados/sbrt_txts/dossies"
#leitura de todos os dados do diretorio para um dataframe
txtdf<-readtext::readtext(dados, encoding = "latin1")
txtdf$text<-sub('.*\nConteúdo',"",txtdf$text)
txtdf$text<-sub('.*\nCONTEÚDO',"",txtdf$text)
txtdf$text<-sub('.*\nTítulo',"",txtdf$text)
txtdf$text<-gsub('[1-9][0-9]* Copyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.sbrt.ibict.br',"",txtdf$text)
txtdf$text<-gsub('[1-9][0-9]* Copyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.respostatecnica.org.br',"", txtdf$text)
txtdf$text<-gsub('[1-9][0-9]*\nCopyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.respostatecnica.org.br',"", txtdf$text)
txtdf$text<-gsub('\nCopyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.sbrt.ibict.br\n\n[1-9][0-9]*',"", txtdf$text)
txtdf$text<-gsub('Disponível em: ',"",txtdf$text)
txtdf$text<-str_replace_all(txtdf$text, "[^[:alnum:].:,?!;]", " ")
txtdf$text<-gsub("\\s+", " ", str_trim(txtdf$text))
txtdf$text<-gsub('Copyright Serviço Brasileiro de Respostas Técnicas SBRT http: www.respostatecnica.org.br [1-9][0-9]*',"",txtdf$text)
txtdf$text<-gsub('INTRODUÇÃO',"",txtdf$text)
txtdf$text<-gsub('Introdução',"",txtdf$text)
txtdf$text<-gsub('www.*.br',"",txtdf$text)
txtdf$text<- iconv(txtdf$text, from = "UTF-8", to = "ASCII//TRANSLIT")
txtdf[358,2]
#leitura de todos os dados do diretorio para um dataframe
txtdf<-readtext::readtext(dados, encoding = "latin1")
txtdf[358,2]
library(formattable)
#tentativa de extração de informações sobre o documento
tx<-strsplit(x=txtdf[358,2], "\\n")[[1]]
#tentativa de extração de informações sobre o documento
tx<-strsplit(x=txtdf[358,2], "\\n")[[1]][2]
tx
#tentativa de extração de informações sobre o documento
tx<-strsplit(x=txtdf[38,2], "\\n")[[1]][2]
#tentativa de extração de informações sobre o documento
tx<-strsplit(x=txtdf[39,2], "\\n")[[1]][2]
#tentativa de extração de informações sobre o documento
tx<-strsplit(x=txtdf[79,2], "\\n")[[1]][2]
#tentativa de extração de informações sobre o documento
tx<-strsplit(x=txtdf[358,2], "\\n")[[1]][2]
#tentativa de extração de informações sobre o documento
tx<-strsplit(x=txtdf[58,2], "\\n")[[1]][2]
#tentativa de extração de informações sobre o documento
tx<-strsplit(x=txtdf[5,2], "\\n")[[1]][2]
tx<-strsplit(x=txtdf[5,2], "\\n")[[1]]
tx[1]
txtdf[5,2]
txtdf[5,2]
titulo<-regmatches( txtdf[5,2], gregexpr("(?<=DOSSIÊ TÉCNICO ).*(?=\n)", txtdf[358,2], perl = TRUE ) )
titulo
View(titulo)
titulo<-regmatches( txtdf[5,2], gregexpr("(?<=DOSSIÊ TÉCNICO).*(?=\n)", txtdf[5,2], perl = TRUE ) )
titulo
titulo<-regmatches( txtdf[5,2], gregexpr("(?<=DOSSIÊ TÉCNICO).*(?=\\n)", txtdf[5,2], perl = TRUE ) )
titulo
titulo<-regmatches( txtdf[59,2], gregexpr("(?<=DOSSIÊ TÉCNICO).*(?=\\n)", txtdf[59,2], perl = TRUE ) )
titulo
txtdf[59,2]
txtdf[59,2]
titulo<-regmatches( txtdf[59,2], gregexpr("(?<=DOSSIÊ TÉCNICO).*(?=\n)", txtdf[59,2], perl = TRUE ) )
titulo
txtdf[59,2]
<ht.*.>
titulo<-regmatches( txtdf[59,2], gregexpr("DOSSIÊ TÉCNICO.*.\n", txtdf[59,2], perl = TRUE ) )
titulo<-regmatches( txtdf[59,2], gregexpr("DOSSIÊ TÉCNICO.*.\n", txtdf[59,2], perl = TRUE ) )
titulo
titulo<-regmatches( txtdf[59,2], gregexpr("DOSSIÊ TÉCNICO.*\n", txtdf[59,2], perl = TRUE ) )
titulo
txtdf[59,2]
titulo<-regmatches( txtdf[59,2], gregexpr("DOSSIÊ TÉCNICO(.*)\\n", txtdf[59,2], perl = TRUE ) )
titulo
titulo<-regmatches( txtdf[59,2], gregexpr("DOSSIÊ TÉCNICO(.*)\n", txtdf[59,2], perl = TRUE ) )
titulo
titulo<-regmatches( txtdf[59,2], gregexpr("DOSSIÊ TÉCNICO(.*)\n", txtdf[59,2], perl = F ) )
titulo
titulo<-regmatches( txtdf[59,2], gregexpr("DOSSIÊ TÉCNICO.*\n", txtdf[59,2], perl = F ) )
titulo
titulo<-regmatches( txtdf[59,2], gregexpr("DOSSIÊ TÉCNICO.*.\n", txtdf[59,2], perl = F ) )
titulo
#tentativa de extração de informações sobre o documento
tx<-strsplit(x=txtdf[59,2], "\n")[[1]][2]
#tentativa de extração de informações sobre o documento
tx<-strsplit(x=txtdf[79,2], "\n")[[1]][2]
#tentativa de extração de informações sobre o documento
tx<-strsplit(x=txtdf[77,2], "\n")[[1]][2]
#tentativa de extração de informações sobre o documento
tx<-strsplit(x=txtdf[37,2], "\n")[[1]][2]
#tentativa de extração de informações sobre o documento
tx<-strsplit(x=txtdf[39,2], "\n")[[1]][2]
#tentativa de extração de informações sobre o documento
tx<-strsplit(x=txtdf[430,2], "\n")[[1]][2]
for (i in 1:len(txtdf$text)){
tx<-strsplit(x=txtdf[i,2], "\n")[[1]][2]
titulo[i]<-tx
}
for (i in 1:length(txtdf$text)){
tx<-strsplit(x=txtdf[i,2], "\n")[[1]][2]
titulo[i]<-tx
}
for (i in 1:length(txtdf$text)){
tx<-strsplit(x=txtdf[i,2], "\n")[[1]][2]
titulo[[i]]<-tx
}
View(titulo)
titulo[[1]]
titulo[[4]]
titulo[[6]]
titulo<-titulo[[1]]
for (i in 1:length(txtdf$text)){
tx<-strsplit(x=txtdf[i,2], "\n")[[1]][2]
titulo[i]<-tx
}
for (i in 1:length(txtdf$text)){
tx<-strsplit(x=txtdf[i,2], "\n")[[1]][2]
titulo[i]<-tx
}
titulo[90]
titulo[99]
txtdf$titulo<-titulo
options("encoding" = "UTF-8")
options(scipen = 999)
library(stringr)
library(tm)
library(SnowballC)
library(lexiconPT)
library(tidytext)
library(tidyverse)
library(magrittr)
library(stm)
library(ggridges)
library(formattable)
dados<-"/home/micael/R_envs/text-mining/dados/sbrt_txts/dossies"
txtdf<-readtext::readtext(dados, encoding = "latin1")
txtdf$text<-sub('.*\nConteúdo',"",txtdf$text)
txtdf$text<-sub('.*\nCONTEÚDO',"",txtdf$text)
txtdf$text<-sub('.*\nTítulo',"",txtdf$text)
txtdf$text<-gsub('[1-9][0-9]* Copyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.sbrt.ibict.br',"",txtdf$text)
txtdf$text<-gsub('[1-9][0-9]* Copyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.respostatecnica.org.br',"", txtdf$text)
txtdf$text<-gsub('[1-9][0-9]*\nCopyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.respostatecnica.org.br',"", txtdf$text)
txtdf$text<-gsub('\nCopyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.sbrt.ibict.br\n\n[1-9][0-9]*',"", txtdf$text)
txtdf$text<-gsub('Disponível em: ',"",txtdf$text)
txtdf$text<-str_replace_all(txtdf$text, "[^[:alnum:].:,?!;]", " ")
txtdf$text<-gsub("\\s+", " ", str_trim(txtdf$text))
txtdf$text<-gsub('Copyright Serviço Brasileiro de Respostas Técnicas SBRT http: www.respostatecnica.org.br [1-9][0-9]*',"",txtdf$text)
txtdf$text<-gsub('INTRODUÇÃO',"",txtdf$text)
txtdf$text<-gsub('Introdução',"",txtdf$text)
txtdf$text<-gsub('www.*.br',"",txtdf$text)
txtdf$text<- iconv(txtdf$text, from = "UTF-8", to = "ASCII//TRANSLIT")
dados<-"/home/micael/R_envs/text-mining/dados/sbrt_txts/dossies"
txtdf<-readtext::readtext(dados, encoding = "latin1")
for (i in 1:length(txtdf$text)){
tx<-strsplit(x=txtdf[i,2], "\n")[[1]][2]
titulo[i]<-tx
}
txtdf$titulo<-titulo
txtdf$text<-sub('.*\nConteúdo',"",txtdf$text)
txtdf$text<-sub('.*\nCONTEÚDO',"",txtdf$text)
txtdf$text<-sub('.*\nTítulo',"",txtdf$text)
txtdf$text<-gsub('[1-9][0-9]* Copyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.sbrt.ibict.br',"",txtdf$text)
txtdf$text<-gsub('[1-9][0-9]* Copyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.respostatecnica.org.br',"", txtdf$text)
txtdf$text<-gsub('[1-9][0-9]*\nCopyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.respostatecnica.org.br',"", txtdf$text)
txtdf$text<-gsub('\nCopyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.sbrt.ibict.br\n\n[1-9][0-9]*',"", txtdf$text)
txtdf$text<-gsub('Disponível em: ',"",txtdf$text)
txtdf$text<-str_replace_all(txtdf$text, "[^[:alnum:].:,?!;]", " ")
txtdf$text<-gsub("\\s+", " ", str_trim(txtdf$text))
txtdf$text<-gsub('Copyright Serviço Brasileiro de Respostas Técnicas SBRT http: www.respostatecnica.org.br [1-9][0-9]*',"",txtdf$text)
txtdf$text<-gsub('INTRODUÇÃO',"",txtdf$text)
txtdf$text<-gsub('Introdução',"",txtdf$text)
txtdf$text<-gsub('www.*.br',"",txtdf$text)
txtdf$text<- iconv(txtdf$text, from = "UTF-8", to = "ASCII//TRANSLIT")
sw_pt_tm <- tm::stopwords("pt") %>% iconv(from = "UTF-8", to = "ASCII//TRANSLIT")
sbrt_sw <- c("http", "senai", "deve","acesso", "brasil", "devem","www.sbrt.ibict.br",
"serviço", "brasileiro", "respostas", "técnicas", "técnico",
"www.respostatecnica.org.br", "pode", "ser","norma","iso", "kg",
"fig", "fonte", "sbrt", "abnt", "nbr", "tecnica")
sw_pt_tm <- c(sbrt_sw, sw_pt_tm)
df_palavra <- txtdf %>%
unnest_tokens(palavra, text) %>%
filter(!palavra %in% sw_pt_tm)
df_palavra %>%
count(palavra) %>%
arrange(desc(n)) %>%
head(50) %>%
formattable()
proc <- stm::textProcessor(txtdf$text, metadata = txtdf, language = "portuguese",
customstopwords = sw_pt_tm)
out <- stm::prepDocuments(proc$documents, proc$vocab, proc$meta,
lower.thresh = 10)
fit <- stm(
documents = out$documents, vocab = out$vocab, data = out$meta,  K = 10,
max.em.its = 75, init.type = "Spectral", verbose = FALSE
)
plot(fit, "summary")
nomes_topicos <- c("1", "2", "3",
"4", "5", "6", "7",
"8", "9", "10")
maior_prob <- apply(fit$theta, 1, max)
topico_doc <- nomes_topicos[apply(fit$theta, 1, which.max)]
df_topico <- txtdf %>%
mutate(maior_prob = maior_prob,
topico = topico_doc)
df_topico %>%
count(topico) %>%
mutate(topico = forcats::fct_reorder(topico, n)) %>%
ggplot(aes(x = topico, y = n)) +
geom_col(fill = "mediumpurple4") +
theme_minimal() +
labs(x = NULL, y = "Documentos",
title = "Quantidade de documentos por tópico") +
coord_flip()
#dataframe com nome do arquivo e tópico
topico_doc<-df_topico %>%
group_by(topico)%>%
#filter(topico == 1)%>%
select(titulo,doc_id, topico, maior_prob)
head(topico_doc)
View(df_topico)
View(topico_doc)
View(df_palavra)
topico_doc<-df_topico %>%
group_by(topico)%>%
arrange(desc(n))%>%
#filter(topico == 1)%>%
select(titulo,doc_id, topico, maior_prob)
topico_doc<-df_topico %>%
group_by(topico)%>%
arrange(desc(maior_prob))%>%
#filter(topico == 1)%>%
select(titulo,doc_id, topico, maior_prob)
View(topico_doc)
topico_doc%>%
filter(topico==6)%>%
head(10)%>%
formattable()
topico_doc%>%
filter(topico==1)%>%
head(10)%>%
formattable()
topico_doc%>%
filter(topico==2)%>%
head(10)%>%
formattable()
topico_doc%>%
filter(topico==3)%>%
head(10)%>%
formattable()
topico_doc%>%
filter(topico==4)%>%
head(10)%>%
formattable()
topico_doc%>%
filter(topico==5)%>%
head(10)%>%
formattable()
topico_doc%>%
filter(topico==6)%>%
head(10)%>%
formattable()
topico_doc%>%
filter(topico==7)%>%
head(10)%>%
formattable()
topico_doc%>%
filter(topico==1)%>%
head(10)%>%
formattable()
topico_doc%>%
filter(topico==9)%>%
head(10)%>%
formattable()
topico_doc%>%
filter(topico==10)%>%
head(10)%>%
formattable()
topico_doc%>%
filter(topico==8)%>%
head(10)%>%
formattable()
gc()
tinytex::install_tinytex()
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE
)
options("encoding" = "UTF-8")
options(scipen = 999)
library(stringr)
library(tm)
library(SnowballC)
#library(lexiconPT)
#library(tidytext)
library(tidyverse)
library(magrittr)
library(stm)
library(ggridges)
#library(formattable)
dados<-"/home/micael/R_envs/text-mining/dados/sbrt_txts/dossies"
txtdf<-readtext::readtext(dados, encoding = "latin1")
titulo<-NULL
for (i in 1:length(txtdf$text)){
tx<-strsplit(x=txtdf[i,2], "\n")[[1]][2]
titulo[i]<-tx
}
txtdf$titulo<-titulo
txtdf$text<-sub('.*\nConteúdo',"",txtdf$text)
txtdf$text<-sub('.*\nCONTEÚDO',"",txtdf$text)
txtdf$text<-sub('.*\nTítulo',"",txtdf$text)
txtdf$text<-gsub('[1-9][0-9]* Copyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.sbrt.ibict.br',"",txtdf$text)
txtdf$text<-gsub('[1-9][0-9]* Copyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.respostatecnica.org.br',"", txtdf$text)
txtdf$text<-gsub('[1-9][0-9]*\nCopyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.respostatecnica.org.br',"", txtdf$text)
txtdf$text<-gsub('\nCopyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.sbrt.ibict.br\n\n[1-9][0-9]*',"", txtdf$text)
txtdf$text<-gsub('Disponível em: ',"",txtdf$text)
txtdf$text<-str_replace_all(txtdf$text, "[^[:alnum:].:,?!;]", " ")
txtdf$text<-gsub("\\s+", " ", str_trim(txtdf$text))
txtdf$text<-gsub('Copyright Serviço Brasileiro de Respostas Técnicas SBRT http: www.respostatecnica.org.br [1-9][0-9]*',"",txtdf$text)
txtdf$text<-gsub('INTRODUÇÃO',"",txtdf$text)
txtdf$text<-gsub('Introdução',"",txtdf$text)
txtdf$text<-gsub('www.*.br',"",txtdf$text)
txtdf$text<- iconv(txtdf$text, from = "UTF-8", to = "ASCII//TRANSLIT")
sw_pt_tm <- tm::stopwords("pt") %>% iconv(from = "UTF-8", to = "ASCII//TRANSLIT")
sbrt_sw <- c("http", "senai", "deve","acesso", "brasil", "devem","www.sbrt.ibict.br",
"serviço", "brasileiro", "respostas", "técnicas", "técnico",
"www.respostatecnica.org.br", "pode", "ser","norma","iso", "kg",
"fig", "fonte", "sbrt", "abnt", "nbr", "tecnica")
sw_pt_tm <- c(sbrt_sw, sw_pt_tm)
df_palavra <- txtdf %>%
unnest_tokens(palavra, text) %>%
filter(!palavra %in% sw_pt_tm)
options("encoding" = "UTF-8")
options(scipen = 999)
library(stringr)
library(tm)
library(SnowballC)
#library(lexiconPT)
library(tidytext)
library(tidyverse)
library(magrittr)
library(stm)
library(ggridges)
#library(formattable)
df_palavra <- txtdf %>%
unnest_tokens(palavra, text) %>%
filter(!palavra %in% sw_pt_tm)
df_palavra %>%
count(palavra) %>%
arrange(desc(n)) %>%
head(50) #%>%
#formattable()
proc <- stm::textProcessor(txtdf$text, metadata = txtdf, language = "portuguese",
customstopwords = sw_pt_tm)
out <- stm::prepDocuments(proc$documents, proc$vocab, proc$meta,
lower.thresh = 10)
options("encoding" = "UTF-8")
options(scipen = 999)
library(stringr)
library(tm)
library(SnowballC)
#library(lexiconPT)
library(tidytext)
library(tidyverse)
library(stm)
library(ggridges)
#library(formattable)
dados<-"/home/micael/R_envs/text-mining/dados/sbrt_txts/dossies"
txtdf<-readtext::readtext(dados, encoding = "latin1")
df_palavra <- txtdf %>%
unnest_tokens(palavra, text) %>%
filter(!palavra %in% sw_pt_tm)
``{r}
txtdf$text<-sub('.*\nConteúdo',"",txtdf$text)
txtdf$text<-sub('.*\nCONTEÚDO',"",txtdf$text)
txtdf$text<-sub('.*\nTítulo',"",txtdf$text)
txtdf$text<-gsub('[1-9][0-9]* Copyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.sbrt.ibict.br',"",txtdf$text)
txtdf$text<-gsub('[1-9][0-9]* Copyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.respostatecnica.org.br',"", txtdf$text)
txtdf$text<-gsub('[1-9][0-9]*\nCopyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.respostatecnica.org.br',"", txtdf$text)
txtdf$text<-gsub('\nCopyright © Serviço Brasileiro de Respostas Técnicas - SBRT - http://www.sbrt.ibict.br\n\n[1-9][0-9]*',"", txtdf$text)
txtdf$text<-gsub('Disponível em: ',"",txtdf$text)
txtdf$text<-gsub('www.+?br',"",txtdf$text)
txtdf$text<-str_replace_all(txtdf$text, "[^[:alnum:].:,?!;]", " ")
txtdf$text<-gsub("\\s+", " ", str_trim(txtdf$text))
txtdf$text<-gsub('Copyright Serviço Brasileiro de Respostas Técnicas SBRT http: www.respostatecnica.org.br [1-9][0-9]*',"",txtdf$text)
txtdf$text<-gsub('INTRODUÇÃO',"",txtdf$text)
txtdf$text<-gsub('Introdução',"",txtdf$text)
txtdf$text<- iconv(txtdf$text, from = "UTF-8", to = "ASCII//TRANSLIT")
# stopwords da lingua portuguesa sem acento
sw_pt_tm <- tm::stopwords("pt") %>% iconv(from = "UTF-8", to = "ASCII//TRANSLIT")
sbrt_sw <- c("http", "senai", "deve","durante","acesso", "brasil", "devem", "pode", "ser","norma","iso", "kg", "fig", "fonte", "sbrt", "abnt", "nbr", "tecnica")
sw_pt <- c(sbrt_sw, sw_pt_tm)
tryTolower <- function(x){
y = NA
try_error = tryCatch(tolower(x), error = function(e) e)
if (!inherits(try_error, 'error'))
y = tolower(x)
return(y)
}
clean.corpus<-function(corpus){
corpus <- tm_map(corpus,content_transformer(tryTolower))
corpus <- tm_map(corpus, removeWords,sbrt_stw)
corpus <-tm_map(corpus, removePunctuation)
corpus <-tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
return(corpus)
}
corpus<-VCorpus(DataframeSource(txtdf))
corpus<-clean.corpus(corpus)
# stopwords da lingua portuguesa sem acento
sw_pt_tm <- tm::stopwords("pt") %>% iconv(from = "UTF-8", to = "ASCII//TRANSLIT")
sbrt_sw <- c("http", "senai", "deve","durante","acesso", "brasil", "devem", "pode", "ser","norma","iso", "kg", "fig", "fonte", "sbrt", "abnt", "nbr", "tecnica")
sw_pt <- c(sbrt_sw, sw_pt_tm)
tryTolower <- function(x){
y = NA
try_error = tryCatch(tolower(x), error = function(e) e)
if (!inherits(try_error, 'error'))
y = tolower(x)
return(y)
}
clean.corpus<-function(corpus){
corpus <- tm_map(corpus,content_transformer(tryTolower))
corpus <- tm_map(corpus, removeWords,sw_pt)
corpus <-tm_map(corpus, removePunctuation)
corpus <-tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
return(corpus)
}
url
